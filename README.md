# PiMobile

A Raspberry Pi–powered system that brings interactivity to a baby mobile.
Through detecting head movement and translating it to to rotation movement of a servo, a visual display is controlled.
The result is a one‑to‑one, response‑contingent link between a baby’s own movement and the outside world.

## Background

Even young infants rapidly learn that their own actions can "make things happen" around them, a capacity known as response-contingent learning.

[Rovee-Colliers 1969 experiment](https://www.sciencedirect.com/science/article/abs/pii/0022096569900253)
exemplifies this phenomenon:
Infants as young as two months had one of their legs connected via a ribbon to an overhead mobile.
When the infant kicked, the mobile moved in direct response.
This setup demonstrated that infants could learn the contingency between their actions and environmental changes, indicating early operant learning and memory capabilities.

Building on this, [Watson and Ramey](https://psycnet.apa.org/record/1973-28652-001)
used a pressure-sensitive pillow wired to a rotating array of colored shapes.
Around 2 month old babys were placed with their heads on pressure-sensitive pillows.
Babies quickly adapted their posture to keep the display turning, demonstrating an emerging sense of agency.

Crucially, contingent feedback elicited longer looking times and signs of positive affect (smiling, coo-ing, vocalizing) whereas identical but non-contingent movements evoked little interest.

